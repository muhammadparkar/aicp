{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tLnnTw9a2SQ1",
    "outputId": "ff091e06-5fb1-45b6-86fb-5d56fca9513b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: optuna in /home/talisman/.local/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/talisman/.local/lib/python3.12/site-packages (from optuna) (1.13.3)\n",
      "Requirement already satisfied: colorlog in /home/talisman/.local/lib/python3.12/site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in /home/talisman/.local/lib/python3.12/site-packages (from optuna) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/talisman/.local/lib/python3.12/site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/talisman/.local/lib/python3.12/site-packages (from optuna) (2.0.35)\n",
      "Requirement already satisfied: tqdm in /home/talisman/.local/lib/python3.12/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /home/talisman/.local/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /home/talisman/.local/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/talisman/.local/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/talisman/.local/lib/python3.12/site-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/talisman/.local/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.12 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giz9L6o53KWZ",
    "outputId": "0d188563-ce9e-42d3-d3fb-ab818e437961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /home/talisman/.local/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in /home/talisman/.local/lib/python3.12/site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/talisman/.local/lib/python3.12/site-packages (from xgboost) (2.22.3)\n",
      "Requirement already satisfied: scipy in /home/talisman/.local/lib/python3.12/site-packages (from xgboost) (1.14.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.12 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5c8VgsxszwB",
    "outputId": "12800312-25c7-462f-b8e4-9fde5d4aff7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 21:42:48,302] A new study created in memory with name: no-name-b16c8e18-bb9e-4a13-91d6-a49385fc22cf\n",
      "[I 2024-11-14 21:42:48,330] Trial 0 finished with value: 0.5158939151112787 and parameters: {'model': 'SVM', 'svm_kernel': 'linear', 'svm_C': 1.3363230537399484}. Best is trial 0 with value: 0.5158939151112787.\n",
      "[I 2024-11-14 21:42:48,429] Trial 1 finished with value: 0.8544477224349976 and parameters: {'model': 'XGBoost', 'learning_rate': 0.16524817081984308, 'max_depth': 4, 'n_estimators': 84, 'min_child_weight': 2, 'subsample': 0.7527678564805768, 'gamma': 1.8819939601823528}. Best is trial 1 with value: 0.8544477224349976.\n",
      "[I 2024-11-14 21:42:49,295] Trial 2 finished with value: 0.8335126638412476 and parameters: {'model': 'XGBoost', 'learning_rate': 0.2831499397661252, 'max_depth': 6, 'n_estimators': 483, 'min_child_weight': 1, 'subsample': 0.8665671773177084, 'gamma': 2.0662912630518098}. Best is trial 1 with value: 0.8544477224349976.\n",
      "[I 2024-11-14 21:42:49,802] Trial 3 finished with value: 0.8822751437540381 and parameters: {'model': 'Random Forest', 'n_estimators': 287, 'max_depth': 15}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:50,062] Trial 4 finished with value: 0.8814403061235172 and parameters: {'model': 'Random Forest', 'n_estimators': 150, 'max_depth': 14}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:50,594] Trial 5 finished with value: 0.7108338090972364 and parameters: {'model': 'Gradient Boosting', 'learning_rate': 0.2685957714750408, 'n_estimators': 282, 'max_depth': 10, 'min_samples_split': 2}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:50,743] Trial 6 finished with value: 0.8502516746520996 and parameters: {'model': 'XGBoost', 'learning_rate': 0.2528465966837926, 'max_depth': 10, 'n_estimators': 130, 'min_child_weight': 9, 'subsample': 0.6932757701147498, 'gamma': 3.2188196354787046}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:51,389] Trial 7 finished with value: 0.8798134630306595 and parameters: {'model': 'Random Forest', 'n_estimators': 372, 'max_depth': 15}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:51,578] Trial 8 finished with value: 0.8363229773790658 and parameters: {'model': 'Gradient Boosting', 'learning_rate': 0.0199456169931284, 'n_estimators': 132, 'max_depth': 6, 'min_samples_split': 8}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:52,213] Trial 9 finished with value: 0.8805584791107948 and parameters: {'model': 'Random Forest', 'n_estimators': 317, 'max_depth': 15}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:52,219] Trial 10 finished with value: 0.7133944270278739 and parameters: {'model': 'Linear Regression'}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:52,651] Trial 11 finished with value: 0.8784268955840352 and parameters: {'model': 'Random Forest', 'n_estimators': 228, 'max_depth': 20}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:53,054] Trial 12 finished with value: 0.8780398019773828 and parameters: {'model': 'Random Forest', 'n_estimators': 212, 'max_depth': 15}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:53,843] Trial 13 finished with value: 0.87658840098969 and parameters: {'model': 'Random Forest', 'n_estimators': 409, 'max_depth': 19}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:53,847] Trial 14 finished with value: 0.7133944270278739 and parameters: {'model': 'Linear Regression'}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:53,881] Trial 15 finished with value: -0.040355818000963106 and parameters: {'model': 'SVM', 'svm_kernel': 'rbf', 'svm_C': 9.61498557947678}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:54,245] Trial 16 finished with value: 0.8721235207590572 and parameters: {'model': 'Random Forest', 'n_estimators': 197, 'max_depth': 13}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:54,717] Trial 17 finished with value: 0.8771406558010898 and parameters: {'model': 'Random Forest', 'n_estimators': 281, 'max_depth': 18}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:55,324] Trial 18 finished with value: 0.8778964629112841 and parameters: {'model': 'Random Forest', 'n_estimators': 365, 'max_depth': 13}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:55,330] Trial 19 finished with value: 0.7133944270278739 and parameters: {'model': 'Linear Regression'}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:55,358] Trial 20 finished with value: -0.01784705645889506 and parameters: {'model': 'SVM', 'svm_kernel': 'poly', 'svm_C': 6.703967149073693}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:55,911] Trial 21 finished with value: 0.8786341739048722 and parameters: {'model': 'Random Forest', 'n_estimators': 322, 'max_depth': 16}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:56,550] Trial 22 finished with value: 0.8806537844940768 and parameters: {'model': 'Random Forest', 'n_estimators': 320, 'max_depth': 17}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:57,036] Trial 23 finished with value: 0.878918502506033 and parameters: {'model': 'Random Forest', 'n_estimators': 252, 'max_depth': 17}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:57,357] Trial 24 finished with value: 0.8053799967280811 and parameters: {'model': 'Gradient Boosting', 'learning_rate': 0.019090590929623813, 'n_estimators': 160, 'max_depth': 9, 'min_samples_split': 10}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:58,177] Trial 25 finished with value: 0.878603862123937 and parameters: {'model': 'Random Forest', 'n_estimators': 437, 'max_depth': 13}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:58,805] Trial 26 finished with value: 0.8726620403136615 and parameters: {'model': 'Random Forest', 'n_estimators': 351, 'max_depth': 17}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:59,277] Trial 27 finished with value: 0.8785194501983875 and parameters: {'model': 'Random Forest', 'n_estimators': 242, 'max_depth': 12}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:59,626] Trial 28 finished with value: 0.8773875461384409 and parameters: {'model': 'Random Forest', 'n_estimators': 181, 'max_depth': 14}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:59,663] Trial 29 finished with value: -0.059417573416318925 and parameters: {'model': 'SVM', 'svm_kernel': 'rbf', 'svm_C': 0.5067411490085592}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:42:59,669] Trial 30 finished with value: 0.7133944270278739 and parameters: {'model': 'Linear Regression'}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:00,242] Trial 31 finished with value: 0.8812976857170658 and parameters: {'model': 'Random Forest', 'n_estimators': 321, 'max_depth': 16}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:00,867] Trial 32 finished with value: 0.8754474814323479 and parameters: {'model': 'Random Forest', 'n_estimators': 333, 'max_depth': 17}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:00,929] Trial 33 finished with value: 0.8542149662971497 and parameters: {'model': 'XGBoost', 'learning_rate': 0.11263972987897423, 'max_depth': 3, 'n_estimators': 52, 'min_child_weight': 9, 'subsample': 0.5078016744362297, 'gamma': 4.861087390730576}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:01,448] Trial 34 finished with value: 0.8801857577439219 and parameters: {'model': 'Random Forest', 'n_estimators': 280, 'max_depth': 19}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:01,904] Trial 35 finished with value: 0.8211759328842163 and parameters: {'model': 'XGBoost', 'learning_rate': 0.160629110014499, 'max_depth': 7, 'n_estimators': 419, 'min_child_weight': 5, 'subsample': 0.957952588583874, 'gamma': 0.12348160556150889}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:02,396] Trial 36 finished with value: 0.7714390067047497 and parameters: {'model': 'Gradient Boosting', 'learning_rate': 0.09492660819343232, 'n_estimators': 299, 'max_depth': 7, 'min_samples_split': 3}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:02,858] Trial 37 finished with value: 0.8784327180109277 and parameters: {'model': 'Random Forest', 'n_estimators': 266, 'max_depth': 16}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:03,555] Trial 38 finished with value: 0.8139688968658447 and parameters: {'model': 'XGBoost', 'learning_rate': 0.21969253949560275, 'max_depth': 5, 'n_estimators': 379, 'min_child_weight': 5, 'subsample': 0.5463657311049868, 'gamma': 0.05219077316294651}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:04,084] Trial 39 finished with value: 0.8744301979648146 and parameters: {'model': 'Random Forest', 'n_estimators': 302, 'max_depth': 14}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:04,958] Trial 40 finished with value: 0.7485394996015756 and parameters: {'model': 'Gradient Boosting', 'learning_rate': 0.07244703783086952, 'n_estimators': 475, 'max_depth': 9, 'min_samples_split': 5}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:05,546] Trial 41 finished with value: 0.8776294109081555 and parameters: {'model': 'Random Forest', 'n_estimators': 329, 'max_depth': 15}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:06,064] Trial 42 finished with value: 0.878792947524303 and parameters: {'model': 'Random Forest', 'n_estimators': 306, 'max_depth': 16}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:06,640] Trial 43 finished with value: 0.8774299834478185 and parameters: {'model': 'Random Forest', 'n_estimators': 345, 'max_depth': 14}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:07,303] Trial 44 finished with value: 0.8775006413653348 and parameters: {'model': 'Random Forest', 'n_estimators': 391, 'max_depth': 11}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:07,341] Trial 45 finished with value: 0.5273020885577037 and parameters: {'model': 'SVM', 'svm_kernel': 'linear', 'svm_C': 4.487902763236622}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:07,875] Trial 46 finished with value: 0.8789695246013931 and parameters: {'model': 'Random Forest', 'n_estimators': 314, 'max_depth': 18}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:08,491] Trial 47 finished with value: 0.8772384458288751 and parameters: {'model': 'Random Forest', 'n_estimators': 356, 'max_depth': 15}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:08,496] Trial 48 finished with value: 0.7133944270278739 and parameters: {'model': 'Linear Regression'}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:08,746] Trial 49 finished with value: 0.8724372989693786 and parameters: {'model': 'Random Forest', 'n_estimators': 148, 'max_depth': 12}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:09,119] Trial 50 finished with value: 0.8773600905603868 and parameters: {'model': 'Random Forest', 'n_estimators': 224, 'max_depth': 16}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:09,584] Trial 51 finished with value: 0.8813848542503333 and parameters: {'model': 'Random Forest', 'n_estimators': 282, 'max_depth': 20}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:10,040] Trial 52 finished with value: 0.876131771083289 and parameters: {'model': 'Random Forest', 'n_estimators': 258, 'max_depth': 19}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:10,560] Trial 53 finished with value: 0.8794103012051462 and parameters: {'model': 'Random Forest', 'n_estimators': 291, 'max_depth': 18}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:11,021] Trial 54 finished with value: 0.8816342060313433 and parameters: {'model': 'Random Forest', 'n_estimators': 274, 'max_depth': 20}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:11,529] Trial 55 finished with value: 0.8780952824685113 and parameters: {'model': 'Random Forest', 'n_estimators': 275, 'max_depth': 20}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:11,943] Trial 56 finished with value: 0.8787220519822905 and parameters: {'model': 'Random Forest', 'n_estimators': 239, 'max_depth': 20}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:12,121] Trial 57 finished with value: 0.7765808949232773 and parameters: {'model': 'Gradient Boosting', 'learning_rate': 0.20391083937298798, 'n_estimators': 97, 'max_depth': 8, 'min_samples_split': 6}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:12,151] Trial 58 finished with value: -0.0004631883733761111 and parameters: {'model': 'SVM', 'svm_kernel': 'poly', 'svm_C': 9.530785560058037}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:12,472] Trial 59 finished with value: 0.879377066243509 and parameters: {'model': 'Random Forest', 'n_estimators': 190, 'max_depth': 19}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:12,593] Trial 60 finished with value: 0.8639601469039917 and parameters: {'model': 'XGBoost', 'learning_rate': 0.13293663570404812, 'max_depth': 9, 'n_estimators': 118, 'min_child_weight': 7, 'subsample': 0.6666776592733572, 'gamma': 4.950216765139058}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:13,184] Trial 61 finished with value: 0.879258602809154 and parameters: {'model': 'Random Forest', 'n_estimators': 338, 'max_depth': 15}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:13,702] Trial 62 finished with value: 0.879701868563163 and parameters: {'model': 'Random Forest', 'n_estimators': 316, 'max_depth': 17}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:14,080] Trial 63 finished with value: 0.8804814515397937 and parameters: {'model': 'Random Forest', 'n_estimators': 216, 'max_depth': 18}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:14,085] Trial 64 finished with value: 0.7133944270278739 and parameters: {'model': 'Linear Regression'}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:14,584] Trial 65 finished with value: 0.873465512325114 and parameters: {'model': 'Random Forest', 'n_estimators': 289, 'max_depth': 14}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:15,031] Trial 66 finished with value: 0.8760308328031201 and parameters: {'model': 'Random Forest', 'n_estimators': 268, 'max_depth': 16}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:15,420] Trial 67 finished with value: 0.8801563804627666 and parameters: {'model': 'Random Forest', 'n_estimators': 246, 'max_depth': 13}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:15,947] Trial 68 finished with value: 0.873839571226217 and parameters: {'model': 'Random Forest', 'n_estimators': 322, 'max_depth': 17}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:16,538] Trial 69 finished with value: 0.8752275449698728 and parameters: {'model': 'Random Forest', 'n_estimators': 362, 'max_depth': 19}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:16,571] Trial 70 finished with value: 0.5259200550005898 and parameters: {'model': 'SVM', 'svm_kernel': 'linear', 'svm_C': 3.778530132828852}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:16,871] Trial 71 finished with value: 0.8721725565473225 and parameters: {'model': 'Random Forest', 'n_estimators': 171, 'max_depth': 18}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:17,304] Trial 72 finished with value: 0.8811960698149713 and parameters: {'model': 'Random Forest', 'n_estimators': 212, 'max_depth': 20}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:17,822] Trial 73 finished with value: 0.8814608558333559 and parameters: {'model': 'Random Forest', 'n_estimators': 289, 'max_depth': 20}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:18,347] Trial 74 finished with value: 0.8756544793030345 and parameters: {'model': 'Random Forest', 'n_estimators': 293, 'max_depth': 20}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:18,761] Trial 75 finished with value: 0.8760009877205782 and parameters: {'model': 'Random Forest', 'n_estimators': 207, 'max_depth': 20}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:19,486] Trial 76 finished with value: 0.8774797874899105 and parameters: {'model': 'Random Forest', 'n_estimators': 233, 'max_depth': 19}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:20,096] Trial 77 finished with value: 0.8390056239887018 and parameters: {'model': 'Gradient Boosting', 'learning_rate': 0.06790946032583235, 'n_estimators': 258, 'max_depth': 5, 'min_samples_split': 10}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:23,228] Trial 78 finished with value: 0.8306367993354797 and parameters: {'model': 'XGBoost', 'learning_rate': 0.2029490433635345, 'max_depth': 9, 'n_estimators': 280, 'min_child_weight': 3, 'subsample': 0.9967936315279776, 'gamma': 3.4480413009752464}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:23,803] Trial 79 finished with value: 0.877660673920483 and parameters: {'model': 'Random Forest', 'n_estimators': 304, 'max_depth': 19}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:23,808] Trial 80 finished with value: 0.7133944270278739 and parameters: {'model': 'Linear Regression'}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:24,388] Trial 81 finished with value: 0.8812124177759014 and parameters: {'model': 'Random Forest', 'n_estimators': 332, 'max_depth': 15}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:24,970] Trial 82 finished with value: 0.8748566316842944 and parameters: {'model': 'Random Forest', 'n_estimators': 327, 'max_depth': 20}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:25,549] Trial 83 finished with value: 0.8813601759222474 and parameters: {'model': 'Random Forest', 'n_estimators': 338, 'max_depth': 15}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:26,120] Trial 84 finished with value: 0.8792850382311596 and parameters: {'model': 'Random Forest', 'n_estimators': 344, 'max_depth': 14}. Best is trial 3 with value: 0.8822751437540381.\n",
      "[I 2024-11-14 21:43:26,650] Trial 85 finished with value: 0.8847580309625788 and parameters: {'model': 'Random Forest', 'n_estimators': 307, 'max_depth': 15}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:27,269] Trial 86 finished with value: 0.877525279509838 and parameters: {'model': 'Random Forest', 'n_estimators': 381, 'max_depth': 15}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:27,785] Trial 87 finished with value: 0.8779760626325495 and parameters: {'model': 'Random Forest', 'n_estimators': 304, 'max_depth': 13}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:28,404] Trial 88 finished with value: 0.8801518086196084 and parameters: {'model': 'Random Forest', 'n_estimators': 369, 'max_depth': 16}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:28,927] Trial 89 finished with value: 0.877418421479079 and parameters: {'model': 'Random Forest', 'n_estimators': 312, 'max_depth': 15}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:29,516] Trial 90 finished with value: 0.8765556050978155 and parameters: {'model': 'Random Forest', 'n_estimators': 341, 'max_depth': 12}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:29,965] Trial 91 finished with value: 0.8780150932710261 and parameters: {'model': 'Random Forest', 'n_estimators': 271, 'max_depth': 14}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:30,422] Trial 92 finished with value: 0.8751123648799227 and parameters: {'model': 'Random Forest', 'n_estimators': 284, 'max_depth': 11}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:30,671] Trial 93 finished with value: 0.8758199715677675 and parameters: {'model': 'Random Forest', 'n_estimators': 148, 'max_depth': 20}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:31,205] Trial 94 finished with value: 0.8786483562972157 and parameters: {'model': 'Random Forest', 'n_estimators': 331, 'max_depth': 16}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:31,612] Trial 95 finished with value: 0.8774740170089922 and parameters: {'model': 'Random Forest', 'n_estimators': 257, 'max_depth': 15}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:31,846] Trial 96 finished with value: 0.7997212270591054 and parameters: {'model': 'Gradient Boosting', 'learning_rate': 0.2412948900589622, 'n_estimators': 294, 'max_depth': 3, 'min_samples_split': 4}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:31,881] Trial 97 finished with value: -0.04610110460750283 and parameters: {'model': 'SVM', 'svm_kernel': 'rbf', 'svm_C': 6.851296912068693}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:32,434] Trial 98 finished with value: 0.8816453866956444 and parameters: {'model': 'Random Forest', 'n_estimators': 313, 'max_depth': 19}. Best is trial 85 with value: 0.8847580309625788.\n",
      "[I 2024-11-14 21:43:32,968] Trial 99 finished with value: 0.8264700174331665 and parameters: {'model': 'XGBoost', 'learning_rate': 0.297156295538764, 'max_depth': 6, 'n_estimators': 400, 'min_child_weight': 10, 'subsample': 0.8374047937153741, 'gamma': 1.3031436783669428}. Best is trial 85 with value: 0.8847580309625788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Metrics-----\n",
      "\n",
      "Evaluating Random Forest...\n",
      "Random Forest MSE: 5360037.0301\n",
      "Random Forest RMSE: 2315.1754\n",
      "Random Forest R-squared: 0.8743\n",
      "Random Forest MAPE: 4.48%\n",
      "\n",
      "Evaluating SVM...\n",
      "SVM MSE: 20710921.6290\n",
      "SVM RMSE: 4550.9254\n",
      "SVM R-squared: 0.5143\n",
      "SVM MAPE: 12.04%\n",
      "\n",
      "Evaluating XGBoost...\n",
      "XGBoost MSE: 8532286.8836\n",
      "XGBoost RMSE: 2921.0079\n",
      "XGBoost R-squared: 0.7999\n",
      "XGBoost MAPE: 4.73%\n",
      "\n",
      "Evaluating Linear Regression...\n",
      "Linear Regression MSE: 12221661.7059\n",
      "Linear Regression RMSE: 3495.9493\n",
      "Linear Regression R-squared: 0.7134\n",
      "Linear Regression MAPE: 10.96%\n",
      "\n",
      "Evaluating Gradient Boosting...\n",
      "Gradient Boosting MSE: 13229603.1147\n",
      "Gradient Boosting RMSE: 3637.2521\n",
      "Gradient Boosting R-squared: 0.6898\n",
      "Gradient Boosting MAPE: 4.97%\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('test.csv')\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('PremiumPrice', axis=1)  # Features (all columns except target)\n",
    "y = data['PremiumPrice']                # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    model_name = trial.suggest_categorical('model', ['Random Forest', 'XGBoost', 'Linear Regression', 'SVM', 'Gradient Boosting'])\n",
    "\n",
    "    if model_name == 'Random Forest':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 20)\n",
    "        }\n",
    "        model = RandomForestRegressor(**params)\n",
    "\n",
    "    elif model_name == 'XGBoost':\n",
    "        params = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5)\n",
    "        }\n",
    "        model = XGBRegressor(**params)\n",
    "\n",
    "    elif model_name == 'SVM':\n",
    "        params = {\n",
    "            'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'rbf', 'poly']),\n",
    "            'C': trial.suggest_float('svm_C', 0.1, 10.0)\n",
    "        }\n",
    "        model = SVR(**params)\n",
    "\n",
    "    elif model_name == 'Gradient Boosting':\n",
    "        params = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10)\n",
    "        }\n",
    "        model = GradientBoostingRegressor(**params)\n",
    "\n",
    "    else:  # Linear Regression\n",
    "        model = LinearRegression()\n",
    "\n",
    "    # Fit the model and make predictions\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred) * 100  # MAPE as percentage\n",
    "\n",
    "    return r2  # Return R-squared value for optimization\n",
    "\n",
    "# Create the Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nModel Performance Metrics-----\")\n",
    "\n",
    "# Evaluate and print results for each modelMedicalpremium\n",
    "\n",
    "    # Initialize and fit the model with the best parameters\n",
    "    if model_name == 'Random Forest':\n",
    "        best_model = RandomForestRegressor(n_estimators=study.best_params.get('n_estimators', 100),\n",
    "                                            max_depth=study.best_params.get('max_depth', 10))\n",
    "    elif model_name == 'XGBoost':\n",
    "        best_model = XGBRegressor(\n",
    "            learning_rate=study.best_params.get('learning_rate', 0.1),\n",
    "            max_depth=study.best_params.get('max_depth', 3),\n",
    "            n_estimators=study.best_params.get('n_estimators', 100),\n",
    "            min_child_weight=study.best_params.get('min_child_weight', 1),\n",
    "            subsample=study.best_params.get('subsample', 1.0),\n",
    "            gamma=study.best_params.get('gamma', 0)\n",
    "        )\n",
    "    elif model_name == 'SVM':\n",
    "        best_model = SVR(\n",
    "            kernel=study.best_params.get('svm_kernel', 'linear'),\n",
    "            C=study.best_params.get('svm_C', 1.0)\n",
    "        )\n",
    "    elif model_name == 'Gradient Boosting':\n",
    "        best_model = GradientBoostingRegressor(\n",
    "            learning_rate=study.best_params.get('learning_rate', 0.1),\n",
    "            n_estimators=study.best_params.get('n_estimators', 100),\n",
    "            max_depth=study.best_params.get('max_depth', 3),\n",
    "            min_samples_split=study.best_params.get('min_samples_split', 2)\n",
    "        )\n",
    "    else:  # Linear Regression\n",
    "        best_model = LinearRegression()\n",
    "\n",
    "    # Fit the model and make predictions\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred) * 100  # MAPE as percentage\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"{model_name} MSE: {mse:.4f}\")\n",
    "    print(f\"{model_name} RMSE: {rmse:.4f}\")\n",
    "    print(f\"{model_name} R-squared: {r2:.4f}\")\n",
    "    print(f\"{model_name} MAPE: {mape:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
